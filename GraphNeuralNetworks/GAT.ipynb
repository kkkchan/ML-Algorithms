{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用Tensoflow2实现GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "import networkx as nx\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 数据导入\n",
    "\n",
    "依旧使用Cora数据集，跟GCN的实现中一样，所有这里仅仅只是把GCN实现中的代码搬了过来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_path = '../datasets/cora/cora.content'\n",
    "cite_path = '../datasets/cora/cora.cites'\n",
    "data_dir = '../datasets/cora'\n",
    "os.path.exists(content_path), os.path.exists(cite_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(content_path, 'r') as f:\n",
    "    contents = f.readlines()\n",
    "with open(cite_path, 'r') as f:\n",
    "    cites = f.readlines()\n",
    "contents = np.array([l.strip().split('\\t') for l in contents])\n",
    "cites_raw = np.array([i.strip().split('\\t') for i in cites])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============图数据信息=============\n",
      "节点数量： 2708\n",
      "边数量： 5429\n",
      "特征维数： 1433\n",
      "标签类别数量： 7\n",
      "标签类别：\n",
      "     - Case_Based\n",
      "     - Genetic_Algorithms\n",
      "     - Neural_Networks\n",
      "     - Probabilistic_Methods\n",
      "     - Reinforcement_Learning\n",
      "     - Rule_Learning\n",
      "     - Theory\n"
     ]
    }
   ],
   "source": [
    "papers_raw, features_raw, labels_raw = np.split(contents, [1, -1], axis=1)\n",
    "features = features_raw.astype(np.float32)\n",
    "\n",
    "paper_dict = {key:value for value, key in enumerate(np.squeeze(papers_raw))}\n",
    "label_dict = {key:value for value, key in enumerate(np.unique(np.squeeze(labels_raw)))}\n",
    "\n",
    "papers = np.array([[paper_dict[key]] for key in papers_raw.reshape(-1)])\n",
    "labels = np.array([[label_dict[key]] for key in labels_raw.reshape(-1)])\n",
    "\n",
    "cites = np.array([[paper_dict[i[0]], paper_dict[i[1]]] for i in cites_raw])\n",
    "node_num = len(papers)\n",
    "label_num = len(label_dict.keys())\n",
    "feature_dim = features.shape[1]\n",
    "edge_num = len(cites)\n",
    "\n",
    "print('{:=^30}'.format('图数据信息'))\n",
    "print('节点数量：', node_num)\n",
    "print('边数量：', edge_num)\n",
    "print('特征维数：', feature_dim)\n",
    "print('标签类别数量：', label_num)\n",
    "print('标签类别：')\n",
    "for label in label_dict.keys():\n",
    "    print('{: <5}- {:<}'.format('', label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Case_Based': 0,\n",
       " 'Genetic_Algorithms': 1,\n",
       " 'Neural_Networks': 2,\n",
       " 'Probabilistic_Methods': 3,\n",
       " 'Reinforcement_Learning': 4,\n",
       " 'Rule_Learning': 5,\n",
       " 'Theory': 6}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2708, 1), (2708, 1), (5429, 2), (2708, 1433))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.shape, labels.shape, cites.shape, features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 5429, 7, 1433)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_num, edge_num, label_num, feature_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 构造邻接矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(len(papers)))\n",
    "G.add_edges_from(cites)\n",
    "adj_matrix = nx.adjacency_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2708, 2708), scipy.sparse.csr.csr_matrix)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix.shape, type(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将稀疏矩阵转为普通矩阵，并引入自环边，构造带自环的邻接矩阵\n",
    "A = adj_matrix.toarray()\n",
    "A = A + np.eye(A.shape[0])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "节点数：2708\n"
     ]
    }
   ],
   "source": [
    "print(f'节点数：{node_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 数据集分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用同论文中相同的数据集分割方式：\n",
    "- 训练集：**每个类别中取出20个**作为训练集（共140）\n",
    "- 验证集：剩下数据集中取出**500个**\n",
    "- 测试集：剩下数据集中取出**1000个**\n",
    "\n",
    "由于计算时是需要所有的图数据和特征，所以数据集分割采用的是mask数组，**只在算损失和准确率时使用**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ = labels.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建训练、验证、测试索引集合\n",
    "train_index, valid_index, test_index = [], [], []\n",
    "# 每类取出20个样本\n",
    "for cate in label_dict.values():\n",
    "    indexes = np.arange(node_num)\n",
    "    indexes = indexes[labels_ == cate]\n",
    "    indexes = np.random.choice(indexes, 20, replace=False)\n",
    "    train_index.append(indexes)\n",
    "train_index = np.hstack(train_index)\n",
    "np.random.shuffle(train_index)\n",
    "valid_index = np.random.choice(np.setdiff1d(np.arange(node_num), train_index), 500, replace=False)\n",
    "test_index = np.random.choice(reduce(np.setdiff1d, [np.arange(node_num), train_index, valid_index]), \n",
    "                             1000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(shape=(node_num))\n",
    "train_mask = mask.copy()\n",
    "valid_mask = mask.copy()\n",
    "test_mask = mask.copy()\n",
    "\n",
    "train_mask[train_index] = 1\n",
    "valid_mask[valid_index] = 1\n",
    "test_mask[test_index] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "数据集分割完成\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================数据导入完成======================\n"
     ]
    }
   ],
   "source": [
    "# 为方便后续使用，将处理好的数据进行离线保存\n",
    "cora_data = {'features': features, 'labels': labels, 'A': A,\n",
    "       'train_mask': train_mask, 'valid_mask': valid_mask, 'test_mask': test_mask, 'node_num': node_num, \n",
    "       'edge_num': edge_num, 'label_num': label_num, 'feature_dim': feature_dim}\n",
    "\n",
    "import pickle \n",
    "pickle.dump(cora_data, open(os.path.join(data_dir, 'cora_data.pkl'), 'wb'))\n",
    "print('{:=^50}'.format('数据导入完成'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'labels': array([[2],\n",
       "        [5],\n",
       "        [4],\n",
       "        ...,\n",
       "        [1],\n",
       "        [0],\n",
       "        [2]]),\n",
       " 'A': array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]]),\n",
       " 'train_mask': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       " 'valid_mask': array([0., 0., 0., ..., 1., 0., 0.]),\n",
       " 'test_mask': array([1., 1., 0., ..., 0., 0., 0.]),\n",
       " 'node_num': 2708,\n",
       " 'edge_num': 5429,\n",
       " 'label_num': 7,\n",
       " 'feature_dim': 1433}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 模型层构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAT实验设置：\n",
    "\n",
    "- 参数初始化：Glorot\n",
    "- 优化算法：Adam\n",
    "- 学习率：0.005\n",
    "- 提早停止：True\n",
    "- epochs：100\n",
    "- 层数：2\n",
    "- 第一层：8heads，$F\\prime = 8$，64个输出特征，ELU作激活函数\n",
    "- 第二层：1heads，$F\\prime = classes$，$classes$个输出特征，softmax激活函数\n",
    "- 正则化：L2，$\\lambda = 0.0005$\n",
    "- Dropout：0.6，用在每层输入和**规范化注意力系数**\n",
    "\n",
    "GCN实验设置：\n",
    "\n",
    "计算公式：$$Z = softmax(\\hat A ReLU(\\hat A X W^{(0)})W^{(1)}))$$\n",
    "\n",
    "- Dropout：0.5，所有层\n",
    "- 正则化：L2，$\\lambda = 0.0005$，第一层\n",
    "- 隐层数：1\n",
    "- 隐层神经元数：16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT_conv(keras.layers.Layer):\n",
    "    def __init__(self, units, \n",
    "                 activation='elu', \n",
    "                 use_bias=False, \n",
    "                 attention_heads=1, \n",
    "                 attention_reduction='concat', \n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None, \n",
    "                 attn_kernel_regularizer=None, \n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None, \n",
    "                 attn_kernel_constraint=None,\n",
    "                 dropout_rate=0.6, \n",
    "                 kernel_initializer='glorot_uniform', \n",
    "                 bias_initializer='zeros', \n",
    "                 **kwargs):\n",
    "        self.units = units\n",
    "        self.attention_heads = attention_heads\n",
    "        self.attention_reduction = attention_reduction\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.use_bias = use_bias\n",
    "        self.bias_initializer = bias_initializer\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        \n",
    "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n",
    "        self.attn_kernel_regularizer = keras.regularizers.get(attn_kernel_regularizer)\n",
    "\n",
    "        self.kernel_constraint = keras.constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = keras.constraints.get(bias_constraint)\n",
    "        self.attn_kernel_constraint = keras.constraints.get(attn_kernel_constraint)\n",
    "        \n",
    "        \n",
    "        if attention_reduction == 'concat':\n",
    "            # concat multi-heads\n",
    "            self.output_dim = self.units * self.attention_heads\n",
    "        else:\n",
    "            # average multi-heads\n",
    "            self.output_dim = self.units\n",
    "        \n",
    "        self.kernels = []\n",
    "        self.bias = []\n",
    "        self.attention_kernels = []\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        for head in range(self.attention_heads):\n",
    "            kernel = self.add_weight(shape=(input_shape[0][-1], self.units), \n",
    "                                     initializer=self.kernel_initializer,\n",
    "                                     regularizer=self.activity_regularizer,\n",
    "                                     name='kernel_head{}'.format(head))\n",
    "            self.kernels.append(kernel)\n",
    "            if self.use_bias:\n",
    "                bias = self.add_weight(shape=(self.units, ),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.activity_regularizer,\n",
    "                                      name='bias_head{}'.format(head))\n",
    "                self.bias.append(bias)\n",
    "            \n",
    "            attention_kernel_self = self.add_weight(shape=(self.units, 1),\n",
    "                                                   initializer=self.kernel_initializer,\n",
    "                                                   regularizer=self.attn_kernel_regularizer,\n",
    "                                                   constraint=self.attn_kernel_constraint,\n",
    "                                                   name='attention_kernel_self_head{}'.format(head))\n",
    "            attention_kernel_neighbors = self.add_weight(shape=(self.units, 1),\n",
    "                                                         initializer=self.kernel_initializer,\n",
    "                                                         regularizer=self.attn_kernel_regularizer,\n",
    "                                                         constraint=self.attn_kernel_constraint,\n",
    "                                                         name='attention_kernel_neighbors_head{}'.format(head))\n",
    "            self.attention_kernels.append([attention_kernel_self, attention_kernel_neighbors])\n",
    "            self.built = True\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        X, A = inputs # [nxd, nxn]\n",
    "        outputs = []\n",
    "        for head in range(self.attention_heads):\n",
    "            kernel = self.kernels[head] # dxd'\n",
    "            attention_kernel = self.attention_kernels[head] # [d'x1, d'x1]\n",
    "            \n",
    "            features = X @ kernel # nxd'\n",
    "            attention_self = features @ attention_kernel[0] # nx1\n",
    "            attention_neighbors = features @ attention_kernel[1] # nx1\n",
    "            \n",
    "            \n",
    "            a_weight = attention_self + tf.transpose(attention_neighbors)\n",
    "            a_weight = tf.nn.leaky_relu(a_weight, alpha=0.2)\n",
    "            #  a_weight *= A # 掩码，去掉无连接关系的值\n",
    "            a_weight += -10e9 * (1.0-A) # 处理softmax中的无连接位置的值\n",
    "             \n",
    "            a_weight = tf.nn.softmax(a_weight)\n",
    "            \n",
    "            dropout_attention = keras.layers.Dropout(self.dropout_rate)(a_weight, training=training) # nxn\n",
    "#             dropout_features = keras.layers.Dropout(self.dropout_rate)(features, training=training) # nxd'\n",
    "            dropout_features = keras.layers.Dropout(0.0)(features, training=training) # nxd'\n",
    "\n",
    "            \n",
    "            \n",
    "            node_features = dropout_attention @ dropout_features # nxd'\n",
    "            \n",
    "            if self.use_bias:\n",
    "                node_features += self.bias[head] # nxd'\n",
    "            outputs.append(node_features)\n",
    "            \n",
    "        if self.attention_reduction == 'concat':\n",
    "            output = tf.concat(outputs, axis=1)\n",
    "        else:\n",
    "            output = tf.reduce_mean(outputs, axis=0)\n",
    "        return self.activation(output)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_shape = input_shape[0][0], self.output_dim\n",
    "        return output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 模型层构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gat(hidden_size=64, dropout_rate=0.0, att_heads=8, use_bias=True, l2_reg=tf.keras.regularizers.l2(5e-4/2)):\n",
    "    X_input = keras.Input(shape=(feature_dim, ))\n",
    "    A_input = keras.Input(shape=(node_num, ))\n",
    "    \n",
    "    dropout1 = keras.layers.Dropout(dropout_rate)(X_input)\n",
    "    z = GAT_conv(units=hidden_size, activation='elu', dropout_rate=dropout_rate, kernel_regularizer=l2_reg,\n",
    "                 attention_reduction='concat', \n",
    "                 attention_heads=att_heads)([dropout1, A_input])\n",
    "    dropout2 = keras.layers.Dropout(dropout_rate)(z)\n",
    "    z = GAT_conv(units=label_num, activation='softmax', kernel_regularizer=l2_reg,\n",
    "                 attention_reduction='mean', dropout_rate=dropout_rate, \n",
    "                 attention_heads=1)([dropout2, A_input])\n",
    "    model = keras.Model(inputs=[X_input, A_input], outputs=z, name='GAT_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 模型编译、训练、评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features', 'labels', 'A', 'train_mask', 'valid_mask', 'test_mask', 'node_num', 'edge_num', 'label_num', 'feature_dim'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = cora_data['features']\n",
    "labels = cora_data['labels']\n",
    "\n",
    "features = tf.convert_to_tensor(features, tf.float32)\n",
    "labels = tf.convert_to_tensor(labels, tf.int32)\n",
    "train_mask = tf.cast(cora_data['train_mask'], tf.float32)\n",
    "val_mask = tf.cast(cora_data['valid_mask'], tf.float32)\n",
    "test_mask = tf.cast(cora_data['test_mask'], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 - 1s - loss: 0.1102 - acc: 0.1786 - val_loss: 0.3437 - val_acc: 0.3960\n",
      "Epoch 2/1000\n",
      "1/1 - 0s - loss: 0.1030 - acc: 0.2500 - val_loss: 0.3255 - val_acc: 0.4960\n",
      "Epoch 3/1000\n",
      "1/1 - 0s - loss: 0.0951 - acc: 0.3000 - val_loss: 0.3075 - val_acc: 0.5680\n",
      "Epoch 4/1000\n",
      "1/1 - 0s - loss: 0.0922 - acc: 0.3714 - val_loss: 0.2902 - val_acc: 0.6500\n",
      "Epoch 5/1000\n",
      "1/1 - 0s - loss: 0.0881 - acc: 0.4214 - val_loss: 0.2745 - val_acc: 0.7140\n",
      "Epoch 6/1000\n",
      "1/1 - 0s - loss: 0.0864 - acc: 0.4500 - val_loss: 0.2578 - val_acc: 0.7740\n",
      "Epoch 7/1000\n",
      "1/1 - 0s - loss: 0.0795 - acc: 0.5286 - val_loss: 0.2427 - val_acc: 0.7920\n",
      "Epoch 8/1000\n",
      "1/1 - 0s - loss: 0.0719 - acc: 0.5714 - val_loss: 0.2290 - val_acc: 0.7980\n",
      "Epoch 9/1000\n",
      "1/1 - 0s - loss: 0.0758 - acc: 0.5071 - val_loss: 0.2171 - val_acc: 0.7940\n",
      "Epoch 10/1000\n",
      "1/1 - 0s - loss: 0.0706 - acc: 0.5000 - val_loss: 0.2064 - val_acc: 0.7980\n",
      "Epoch 11/1000\n",
      "1/1 - 0s - loss: 0.0610 - acc: 0.6143 - val_loss: 0.1966 - val_acc: 0.7960\n",
      "Epoch 12/1000\n",
      "1/1 - 0s - loss: 0.0612 - acc: 0.5929 - val_loss: 0.1879 - val_acc: 0.8080\n",
      "Epoch 13/1000\n",
      "1/1 - 0s - loss: 0.0658 - acc: 0.5500 - val_loss: 0.1804 - val_acc: 0.8140\n",
      "Epoch 14/1000\n",
      "1/1 - 0s - loss: 0.0642 - acc: 0.5857 - val_loss: 0.1734 - val_acc: 0.8160\n",
      "Epoch 15/1000\n",
      "1/1 - 0s - loss: 0.0624 - acc: 0.5714 - val_loss: 0.1671 - val_acc: 0.8220\n",
      "Epoch 16/1000\n",
      "1/1 - 0s - loss: 0.0586 - acc: 0.6143 - val_loss: 0.1617 - val_acc: 0.8200\n",
      "Epoch 17/1000\n",
      "1/1 - 0s - loss: 0.0648 - acc: 0.5786 - val_loss: 0.1574 - val_acc: 0.8160\n",
      "Epoch 18/1000\n",
      "1/1 - 0s - loss: 0.0623 - acc: 0.6000 - val_loss: 0.1536 - val_acc: 0.8140\n",
      "Epoch 19/1000\n",
      "1/1 - 0s - loss: 0.0573 - acc: 0.5929 - val_loss: 0.1500 - val_acc: 0.8180\n",
      "Epoch 20/1000\n",
      "1/1 - 0s - loss: 0.0580 - acc: 0.6143 - val_loss: 0.1466 - val_acc: 0.8100\n",
      "Epoch 21/1000\n",
      "1/1 - 0s - loss: 0.0494 - acc: 0.7286 - val_loss: 0.1433 - val_acc: 0.8080\n",
      "Epoch 22/1000\n",
      "1/1 - 0s - loss: 0.0596 - acc: 0.6071 - val_loss: 0.1401 - val_acc: 0.8060\n",
      "Epoch 23/1000\n",
      "1/1 - 0s - loss: 0.0507 - acc: 0.6429 - val_loss: 0.1367 - val_acc: 0.8100\n",
      "Epoch 24/1000\n",
      "1/1 - 0s - loss: 0.0493 - acc: 0.6571 - val_loss: 0.1337 - val_acc: 0.8160\n",
      "Epoch 25/1000\n",
      "1/1 - 0s - loss: 0.0532 - acc: 0.6500 - val_loss: 0.1308 - val_acc: 0.8200\n",
      "Epoch 26/1000\n",
      "1/1 - 0s - loss: 0.0450 - acc: 0.7357 - val_loss: 0.1286 - val_acc: 0.8260\n",
      "Epoch 27/1000\n",
      "1/1 - 0s - loss: 0.0563 - acc: 0.6571 - val_loss: 0.1264 - val_acc: 0.8240\n",
      "Epoch 28/1000\n",
      "1/1 - 0s - loss: 0.0473 - acc: 0.7429 - val_loss: 0.1245 - val_acc: 0.8280\n",
      "Epoch 29/1000\n",
      "1/1 - 0s - loss: 0.0476 - acc: 0.6643 - val_loss: 0.1228 - val_acc: 0.8260\n",
      "Epoch 30/1000\n",
      "1/1 - 0s - loss: 0.0403 - acc: 0.7357 - val_loss: 0.1215 - val_acc: 0.8260\n",
      "Epoch 31/1000\n",
      "1/1 - 0s - loss: 0.0487 - acc: 0.6929 - val_loss: 0.1202 - val_acc: 0.8260\n",
      "Epoch 32/1000\n",
      "1/1 - 0s - loss: 0.0457 - acc: 0.7071 - val_loss: 0.1190 - val_acc: 0.8240\n",
      "Epoch 33/1000\n",
      "1/1 - 0s - loss: 0.0420 - acc: 0.6643 - val_loss: 0.1181 - val_acc: 0.8260\n",
      "Epoch 34/1000\n",
      "1/1 - 0s - loss: 0.0497 - acc: 0.6857 - val_loss: 0.1171 - val_acc: 0.8260\n",
      "Epoch 35/1000\n",
      "1/1 - 0s - loss: 0.0522 - acc: 0.6714 - val_loss: 0.1164 - val_acc: 0.8300\n",
      "Epoch 36/1000\n",
      "1/1 - 0s - loss: 0.0498 - acc: 0.7143 - val_loss: 0.1156 - val_acc: 0.8280\n",
      "Epoch 37/1000\n",
      "1/1 - 0s - loss: 0.0507 - acc: 0.6857 - val_loss: 0.1145 - val_acc: 0.8240\n",
      "Epoch 38/1000\n",
      "1/1 - 0s - loss: 0.0463 - acc: 0.6786 - val_loss: 0.1133 - val_acc: 0.8240\n",
      "Epoch 39/1000\n",
      "1/1 - 0s - loss: 0.0404 - acc: 0.7429 - val_loss: 0.1124 - val_acc: 0.8260\n",
      "Epoch 40/1000\n",
      "1/1 - 0s - loss: 0.0454 - acc: 0.6786 - val_loss: 0.1118 - val_acc: 0.8300\n",
      "Epoch 41/1000\n",
      "1/1 - 0s - loss: 0.0465 - acc: 0.6857 - val_loss: 0.1112 - val_acc: 0.8300\n",
      "Epoch 42/1000\n",
      "1/1 - 0s - loss: 0.0499 - acc: 0.6929 - val_loss: 0.1109 - val_acc: 0.8300\n",
      "Epoch 43/1000\n",
      "1/1 - 0s - loss: 0.0448 - acc: 0.6929 - val_loss: 0.1107 - val_acc: 0.8300\n",
      "Epoch 44/1000\n",
      "1/1 - 0s - loss: 0.0431 - acc: 0.7429 - val_loss: 0.1105 - val_acc: 0.8320\n",
      "Epoch 45/1000\n",
      "1/1 - 0s - loss: 0.0385 - acc: 0.7643 - val_loss: 0.1103 - val_acc: 0.8320\n",
      "\n",
      "1/1 - 0s - loss: 0.0080 - acc: 0.9714\n",
      "[0.00803146418184042, 0.9714285731315613]\n",
      "1/1 - 0s - loss: 0.1103 - acc: 0.8320\n",
      "[0.11029516160488129, 0.8320000171661377]\n",
      "1/1 - 0s - loss: 0.2293 - acc: 0.8210\n",
      "[0.22929000854492188, 0.8209999799728394]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa86c7061f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dropout_rate = 0.7\n",
    "epochs = 1000\n",
    "es_patience = 10\n",
    "es_min_delta = 0.01\n",
    "lr=0.005\n",
    "\n",
    "model = gat(dropout_rate=dropout_rate, use_bias=False)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=lr)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              weighted_metrics=['acc'])\n",
    "\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                            patience=es_patience, \n",
    "                                            min_delta=es_min_delta)\n",
    "\n",
    "val_data = ([features, A], labels, val_mask)\n",
    "history = model.fit([features, A], labels, sample_weight=train_mask, validation_data=val_data,\n",
    "          batch_size=node_num, epochs=epochs, verbose=2, shuffle=False, callbacks=es_callback)\n",
    "print()\n",
    "for i in [train_mask, val_mask, test_mask]:\n",
    "    print(model.evaluate([features, A], labels, sample_weight=i, batch_size=node_num, verbose=2))\n",
    "\n",
    "for i, item in history.history.items():\n",
    "    plt.plot(item, label=i)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.0080 - acc: 0.9714\n",
      "[0.00803146418184042, 0.9714285731315613]\n",
      "1/1 - 0s - loss: 0.1103 - acc: 0.8320\n",
      "[0.11029516160488129, 0.8320000171661377]\n",
      "1/1 - 0s - loss: 0.2293 - acc: 0.8210\n",
      "[0.22929000854492188, 0.8209999799728394]\n"
     ]
    }
   ],
   "source": [
    "for i in [train_mask, val_mask, test_mask]:\n",
    "    print(model.evaluate([features, A], labels, sample_weight=i, batch_size=node_num, verbose=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "自定义损失函数、评估函数和训练\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建损失函数、评估（准确率）函数\n",
    "def masked_sparse_cross_entropy(preds, labels, mask):\n",
    "    \"\"\"预测结果是概率形式，标签是正确类型，计算\"\"\"\n",
    "    mask = tf.cast(mask, tf.bool)\n",
    "    loss = - tf.math.log(tf.clip_by_value(preds[mask], 1e-7, 1)) * tf.one_hot(tf.reshape(labels[mask], shape=(-1, )), 7)\n",
    "    loss = tf.reduce_sum(loss, axis=1)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    '''\n",
    "    或者\n",
    "    keras.losses.SparseCategoricalCrossentropy(from_logits=False)(labels[mask], preds[mask])\n",
    "    '''\n",
    "    return loss\n",
    "\n",
    "def masked_accuracy(preds, labels, mask):\n",
    "    \"\"\"Accuracy with masking.\"\"\"\n",
    "    mask = tf.cast(mask, tf.bool)\n",
    "    correct = tf.equal(tf.cast(tf.argmax(preds[mask], axis=1), dtype=tf.int32), tf.reshape(labels[mask], shape=(-1, )))\n",
    "    correct = tf.cast(correct, tf.float32)\n",
    "    return tf.reduce_mean(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Start of 1====================\n",
      "acc: 0.3499999940395355 - loss: 1.802678108215332 - val_acc: 0.29600000381469727 - val_loss: 1.833546757698059\n",
      "====================Start of 2====================\n",
      "acc: 0.6428571343421936 - loss: 1.6457849740982056 - val_acc: 0.5600000023841858 - val_loss: 1.7034459114074707\n",
      "====================Start of 3====================\n",
      "acc: 0.800000011920929 - loss: 1.4932714700698853 - val_acc: 0.722000002861023 - val_loss: 1.5808579921722412\n",
      "====================Start of 4====================\n",
      "acc: 0.8285714387893677 - loss: 1.3525491952896118 - val_acc: 0.7480000257492065 - val_loss: 1.4678640365600586\n",
      "====================Start of 5====================\n",
      "acc: 0.8500000238418579 - loss: 1.2229682207107544 - val_acc: 0.7580000162124634 - val_loss: 1.364629864692688\n",
      "====================Start of 6====================\n",
      "acc: 0.8714285492897034 - loss: 1.1019967794418335 - val_acc: 0.7839999794960022 - val_loss: 1.2727385759353638\n",
      "====================Start of 7====================\n",
      "acc: 0.8857142925262451 - loss: 0.9938375353813171 - val_acc: 0.8040000200271606 - val_loss: 1.1935070753097534\n",
      "====================Start of 8====================\n",
      "acc: 0.8928571343421936 - loss: 0.8977862000465393 - val_acc: 0.8159999847412109 - val_loss: 1.1264190673828125\n",
      "====================Start of 9====================\n",
      "acc: 0.9142857193946838 - loss: 0.8147887587547302 - val_acc: 0.8100000023841858 - val_loss: 1.070949673652649\n",
      "===================Start of 10====================\n",
      "acc: 0.9142857193946838 - loss: 0.743135929107666 - val_acc: 0.8119999766349792 - val_loss: 1.0236412286758423\n",
      "===================Start of 11====================\n",
      "acc: 0.9142857193946838 - loss: 0.6813100576400757 - val_acc: 0.8140000104904175 - val_loss: 0.9829191565513611\n",
      "===================Start of 12====================\n",
      "acc: 0.9142857193946838 - loss: 0.6266961097717285 - val_acc: 0.8199999928474426 - val_loss: 0.9440868496894836\n",
      "===================Start of 13====================\n",
      "acc: 0.9142857193946838 - loss: 0.578193724155426 - val_acc: 0.8180000185966492 - val_loss: 0.9104682803153992\n",
      "===================Start of 14====================\n",
      "acc: 0.9142857193946838 - loss: 0.5344971418380737 - val_acc: 0.8220000267028809 - val_loss: 0.8757185935974121\n",
      "===================Start of 15====================\n",
      "acc: 0.9214285612106323 - loss: 0.49527183175086975 - val_acc: 0.8220000267028809 - val_loss: 0.8442755937576294\n",
      "===================Start of 16====================\n",
      "acc: 0.9214285612106323 - loss: 0.4603550434112549 - val_acc: 0.8259999752044678 - val_loss: 0.8146970868110657\n",
      "===================Start of 17====================\n",
      "acc: 0.9285714030265808 - loss: 0.42799079418182373 - val_acc: 0.828000009059906 - val_loss: 0.7852447032928467\n",
      "===================Start of 18====================\n",
      "acc: 0.9357143044471741 - loss: 0.4010937809944153 - val_acc: 0.8259999752044678 - val_loss: 0.7596809267997742\n",
      "===================Start of 19====================\n",
      "acc: 0.9428571462631226 - loss: 0.3779476583003998 - val_acc: 0.8299999833106995 - val_loss: 0.738214373588562\n",
      "===================Start of 20====================\n",
      "acc: 0.9428571462631226 - loss: 0.3590986132621765 - val_acc: 0.8299999833106995 - val_loss: 0.7209241986274719\n",
      "===================Start of 21====================\n",
      "acc: 0.949999988079071 - loss: 0.34284520149230957 - val_acc: 0.8259999752044678 - val_loss: 0.7052546143531799\n",
      "===================Start of 22====================\n",
      "acc: 0.949999988079071 - loss: 0.3280024528503418 - val_acc: 0.8259999752044678 - val_loss: 0.6922190189361572\n",
      "===================Start of 23====================\n",
      "acc: 0.949999988079071 - loss: 0.31467723846435547 - val_acc: 0.828000009059906 - val_loss: 0.6823118329048157\n",
      "===================Start of 24====================\n",
      "acc: 0.949999988079071 - loss: 0.30282825231552124 - val_acc: 0.8240000009536743 - val_loss: 0.6754551529884338\n",
      "===================Start of 25====================\n",
      "acc: 0.949999988079071 - loss: 0.29109206795692444 - val_acc: 0.8240000009536743 - val_loss: 0.6682265996932983\n",
      "===================Start of 26====================\n",
      "acc: 0.949999988079071 - loss: 0.2789943516254425 - val_acc: 0.8220000267028809 - val_loss: 0.6610673666000366\n",
      "===================Start of 27====================\n",
      "acc: 0.949999988079071 - loss: 0.2672204077243805 - val_acc: 0.8259999752044678 - val_loss: 0.6537761092185974\n",
      "===================Start of 28====================\n",
      "acc: 0.9571428298950195 - loss: 0.25533103942871094 - val_acc: 0.8220000267028809 - val_loss: 0.6458457112312317\n",
      "===================Start of 29====================\n",
      "acc: 0.9642857313156128 - loss: 0.24515356123447418 - val_acc: 0.8199999928474426 - val_loss: 0.6404195427894592\n",
      "===================Start of 30====================\n",
      "acc: 0.9642857313156128 - loss: 0.23539376258850098 - val_acc: 0.8240000009536743 - val_loss: 0.6356900930404663\n",
      "===================Start of 31====================\n",
      "acc: 0.9642857313156128 - loss: 0.22634708881378174 - val_acc: 0.8220000267028809 - val_loss: 0.6319555044174194\n",
      "===================Start of 32====================\n",
      "acc: 0.9714285731315613 - loss: 0.21846437454223633 - val_acc: 0.8240000009536743 - val_loss: 0.6293426752090454\n",
      "===================Start of 33====================\n",
      "acc: 0.9714285731315613 - loss: 0.21131084859371185 - val_acc: 0.8240000009536743 - val_loss: 0.6273075938224792\n",
      "===================Start of 34====================\n",
      "acc: 0.9714285731315613 - loss: 0.20428958535194397 - val_acc: 0.8240000009536743 - val_loss: 0.6271194815635681\n",
      "===================Start of 35====================\n",
      "acc: 0.9714285731315613 - loss: 0.19772924482822418 - val_acc: 0.8259999752044678 - val_loss: 0.6261724829673767\n",
      "===================Start of 36====================\n",
      "acc: 0.9714285731315613 - loss: 0.19134590029716492 - val_acc: 0.8220000267028809 - val_loss: 0.62605881690979\n",
      "===================Start of 37====================\n",
      "acc: 0.9714285731315613 - loss: 0.18454627692699432 - val_acc: 0.8220000267028809 - val_loss: 0.6240456700325012\n",
      "===================Start of 38====================\n",
      "acc: 0.9714285731315613 - loss: 0.17735174298286438 - val_acc: 0.8220000267028809 - val_loss: 0.6207413673400879\n",
      "===================Start of 39====================\n",
      "acc: 0.9714285731315613 - loss: 0.1701965481042862 - val_acc: 0.8199999928474426 - val_loss: 0.6156331300735474\n",
      "===================Start of 40====================\n",
      "acc: 0.9714285731315613 - loss: 0.16406677663326263 - val_acc: 0.8220000267028809 - val_loss: 0.6121153831481934\n",
      "===================Start of 41====================\n",
      "acc: 0.9714285731315613 - loss: 0.1592549979686737 - val_acc: 0.8220000267028809 - val_loss: 0.60965496301651\n",
      "===================Start of 42====================\n",
      "acc: 0.9714285731315613 - loss: 0.1544794738292694 - val_acc: 0.8240000009536743 - val_loss: 0.605790913105011\n",
      "===================Start of 43====================\n",
      "acc: 0.9714285731315613 - loss: 0.14982789754867554 - val_acc: 0.8240000009536743 - val_loss: 0.6017941236495972\n",
      "===================Start of 44====================\n",
      "acc: 0.9714285731315613 - loss: 0.1454673558473587 - val_acc: 0.8220000267028809 - val_loss: 0.6005094051361084\n",
      "===================Start of 45====================\n",
      "acc: 0.9714285731315613 - loss: 0.14107856154441833 - val_acc: 0.8199999928474426 - val_loss: 0.5985434651374817\n",
      "===================Start of 46====================\n",
      "acc: 0.9714285731315613 - loss: 0.13677695393562317 - val_acc: 0.8220000267028809 - val_loss: 0.5962916612625122\n",
      "===================Start of 47====================\n",
      "acc: 0.9714285731315613 - loss: 0.1327371895313263 - val_acc: 0.8220000267028809 - val_loss: 0.5947348475456238\n",
      "===================Start of 48====================\n",
      "acc: 0.9714285731315613 - loss: 0.12906962633132935 - val_acc: 0.8159999847412109 - val_loss: 0.5939707159996033\n",
      "===================Start of 49====================\n",
      "acc: 0.9714285731315613 - loss: 0.12557443976402283 - val_acc: 0.8180000185966492 - val_loss: 0.5936993360519409\n",
      "===================Start of 50====================\n",
      "acc: 0.9714285731315613 - loss: 0.12215553224086761 - val_acc: 0.8199999928474426 - val_loss: 0.5925429463386536\n",
      "test_acc： 0.816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa83059db80>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dropout_rate = 0.7\n",
    "\n",
    "model = gat(dropout_rate=dropout_rate, use_bias=False)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.005)\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(50):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model([features, A], training=True)\n",
    "        loss = masked_sparse_cross_entropy(logits, labels, train_mask)\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "#     if epoch % 10 == 0:\n",
    "    print('{:=^50}'.format(f'Start of {epoch+1}'))\n",
    "    \n",
    "\n",
    "    # 计算准确率时，关掉dropout\n",
    "    logits = model([features, A], training=False)\n",
    "    loss = masked_sparse_cross_entropy(logits, labels, train_mask)\n",
    "    acc = masked_accuracy(logits, labels, train_mask)\n",
    "    train_accs.append(acc.numpy())\n",
    "    train_losses.append(loss.numpy())\n",
    "    val_acc = masked_accuracy(logits, labels, val_mask)\n",
    "    val_loss = masked_sparse_cross_entropy(logits, labels, val_mask)\n",
    "    val_accs.append(val_acc.numpy())\n",
    "    val_losses.append(val_loss.numpy())\n",
    "    print(f'acc: {acc.numpy()} - loss: {loss} - '\n",
    "          f'val_acc: {val_acc.numpy()} - val_loss: {val_loss}')\n",
    "\n",
    "logits = model([features, A], training=False)\n",
    "acc_test = masked_accuracy(logits, labels, test_mask)\n",
    "print('test_acc：', acc_test.numpy())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_accs)\n",
    "plt.plot(val_accs)\n",
    "plt.legend(['train_acc', 'val_acc'], loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GAT_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 1433)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10748 (Dropout)         (None, 1433)         0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           [(None, 2708)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gat_conv_24 (GAT_conv)          (None, 512)          734720      dropout_10748[0][0]              \n",
      "                                                                 input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10749 (Dropout)         (None, 512)          0           gat_conv_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gat_conv_25 (GAT_conv)          (None, 7)            3598        dropout_10749[0][0]              \n",
      "                                                                 input_26[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 738,318\n",
      "Trainable params: 738,318\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 数据集导入和预处理\n",
    "\n",
    "使用ACM数据集，构造其中的**子集**，**预处理后的数据集参数**如下：\n",
    "- 三个领域：`Database, Wireless Communication, Data Mining`\n",
    "- `Database: SIGMOD, VLDB`\n",
    "- `Data Mining: KDD`\n",
    "- `Wireless Communication: SIGCOMM, MobiCOMM`\n",
    "- 节点类型：`Author, Paper, Subject`\n",
    "- 边类型(无向边)：`Author-Paper, Paper-Author, Author-Subject, Subject-Author`\n",
    "- 元路径：`PAP, PSP`\n",
    "- 半监督学习的学习目标：`Paper-->Conference`\n",
    "- 训练集数量：600(各200)\n",
    "- 验证集数量：300(各100)\n",
    "- 测试集：剩下所有`Paper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../datasets/ACM/ACM.mat')\n",
    "data = sio.loadmat(a_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'TvsP', 'PvsA', 'PvsV', 'AvsF', 'VvsC', 'PvsL', 'PvsC', 'A', 'C', 'F', 'L', 'P', 'T', 'V', 'PvsT', 'CNormPvsA', 'RNormPvsA', 'CNormPvsC', 'RNormPvsC', 'CNormPvsT', 'RNormPvsT', 'CNormPvsV', 'RNormPvsV', 'CNormVvsC', 'RNormVvsC', 'CNormAvsF', 'RNormAvsF', 'CNormPvsL', 'RNormPvsL', 'stopwords', 'nPvsT', 'nT', 'CNormnPvsT', 'RNormnPvsT', 'nnPvsT', 'nnT', 'CNormnnPvsT', 'RNormnnPvsT', 'PvsP', 'CNormPvsP', 'RNormPvsP'])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 生成节点;generating nodes\n",
    "\n",
    "- paper_inx\n",
    "- paper_target\n",
    "\n",
    "数据中，`[0, 1, 9, 10, 13]`分别为：`KDD, SIGMOD, SIGCOMM, MobiCOMM, VLDB`，也即是论文中的所选出的子集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array(['KDD'], dtype='<U3')],\n",
       "       [array(['SIGMOD'], dtype='<U6')],\n",
       "       [array(['WWW'], dtype='<U3')],\n",
       "       [array(['SIGIR'], dtype='<U5')],\n",
       "       [array(['CIKM'], dtype='<U4')],\n",
       "       [array(['SODA'], dtype='<U4')],\n",
       "       [array(['STOC'], dtype='<U4')],\n",
       "       [array(['SOSP'], dtype='<U4')],\n",
       "       [array(['SPAA'], dtype='<U4')],\n",
       "       [array(['SIGCOMM'], dtype='<U7')],\n",
       "       [array(['MobiCOMM'], dtype='<U8')],\n",
       "       [array(['ICML'], dtype='<U4')],\n",
       "       [array(['COLT'], dtype='<U4')],\n",
       "       [array(['VLDB'], dtype='<U4')]], dtype=object)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conferences\n",
    "data['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper vs conference\n",
    "paper_conf = data['PvsC']\n",
    "\n",
    "papers = paper_conf.nonzero()[1]\n",
    "# DataBase: SIGMOD, VLDB;   select 994 papers from total 1994 papers\n",
    "paper_db = np.isin(papers, [1, 13])\n",
    "paper_db_inx = paper_db.nonzero()[0]\n",
    "paper_db_inx = np.sort(np.random.choice(paper_db_inx, 994, replace=False))\n",
    "# DataMining: KDD;  select total 1061 papers\n",
    "paper_dm = np.isin(papers, [0])\n",
    "paper_dm_inx = paper_dm.nonzero()[0]\n",
    "# Wireless Comunication: SIGCOMM, MobiCOMM; select total 970 papers\n",
    "paper_wc = np.isin(papers, [9, 10])\n",
    "paper_wc_inx = paper_wc.nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1994, 1061, 970)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_db.sum(), paper_dm.sum(), paper_wc.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3025,)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then got total 3025 papers, just the same num as the paper(HAN)\n",
    "paper_inx = np.sort(np.concatenate((paper_db_inx, \n",
    "                                    paper_dm_inx, \n",
    "                                    paper_wc_inx), axis=0))\n",
    "paper_inx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 : database, 1: data mining, 2: wireless communication\n",
    "paper_target = np.zeros_like(paper_inx)\n",
    "paper_target[np.isin(paper_inx, paper_dm_inx)] = 1\n",
    "paper_target[np.isin(paper_inx, paper_wc_inx)] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_dict = dict(enumerate(paper_inx))\n",
    "papers = np.array(list(paper_dict.keys()))\n",
    "paper_dict = {key:value for value, key in paper_dict.items()}\n",
    "targets = paper_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3025"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_papers = papers.shape[0]\n",
    "num_papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2生成边；generating edges\n",
    "\n",
    "根据论文中的说明，使用两种元路径：`[PAP, PSP]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_author edges\n",
    "p_a = np.transpose(data['PvsA'][paper_inx].nonzero())\n",
    "# paper_subjects edges\n",
    "p_s = np.transpose(data['PvsL'][paper_inx].nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = np.unique(p_a[:, 1])\n",
    "author_dict = dict(enumerate(authors))\n",
    "author_dict = {key:value+num_papers for value, key in author_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = np.frompyfunc(author_dict.get, 1, 1)(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_authors = authors.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = np.unique(p_s[:, 1])\n",
    "subject_dict = {key:value+num_papers+num_authors for value, key in dict(enumerate(subjects)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = np.frompyfunc(subject_dict.get, 1, 1)(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subjects = subjects.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node = num_papers + num_authors + num_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完成了`authors, subjects`的序号变换，使得`papers, authors, subjects`的整体的序号连续了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_papers_trans = np.vectorize(paper_dict.get)\n",
    "vec_authors_trans = np.vectorize(author_dict.get)\n",
    "vec_subjects_trans = np.vectorize(subject_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "PA = sp.csr_matrix((np.ones_like(p_a[:, 0]), \n",
    "                    (p_a[:, 0], vec_authors_trans(p_a[:, 1]))), \n",
    "                   shape=(num_node, num_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS = sp.csr_matrix((np.ones_like(p_s[:, 0]),\n",
    "                    (p_s[:, 0], vec_subjects_trans(p_s[:, 1]))),\n",
    "                   shape=(num_node, num_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "AP = PA.transpose()\n",
    "SP = PS.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: 9100\n",
      "edges: 13063\n",
      "papers: 3025\n",
      "authors: 6018\n",
      "subjects: 57\n",
      "paper_author edges: (10038, 2)\n",
      "paper_subjects edges: (3025, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'nodes: {nodes.shape[0]}\\n'\\\n",
    "      f'edges: {p_a.shape[0]+p_s.shape[0]}\\n'\\\n",
    "      f'papers: {papers.shape[0]}\\n'\\\n",
    "      f'authors: {authors.shape[0]}\\n'\\\n",
    "      f'subjects: {subjects.shape[0]}\\n'\\\n",
    "      f'paper_author edges: {p_a.shape}\\n'\\\n",
    "      f'paper_subjects edges: {p_s.shape}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 特征构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'TvsP', 'PvsA', 'PvsV', 'AvsF', 'VvsC', 'PvsL', 'PvsC', 'A', 'C', 'F', 'L', 'P', 'T', 'V', 'PvsT', 'CNormPvsA', 'RNormPvsA', 'CNormPvsC', 'RNormPvsC', 'CNormPvsT', 'RNormPvsT', 'CNormPvsV', 'RNormPvsV', 'CNormVvsC', 'RNormVvsC', 'CNormAvsF', 'RNormAvsF', 'CNormPvsL', 'RNormPvsL', 'stopwords', 'nPvsT', 'nT', 'CNormnPvsT', 'RNormnPvsT', 'nnPvsT', 'nnT', 'CNormnnPvsT', 'RNormnnPvsT', 'PvsP', 'CNormPvsP', 'RNormPvsP'])"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_feats = data['TvsP'].transpose()[paper_inx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里有一个细节，如果计算`authors, subjects`的特征？\n",
    "\n",
    "也是基于`papers`的特征信息，具体措施是通过`authors-papers, subjects-papers`矩阵与`papers-terms`矩阵进行**矩阵乘积**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6018, 57)"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_authors, num_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1723, 1991, 4543, ...,  502, 2369, 4829])"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_authors_trans(p_a[:, 1]) - num_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct `authors-papers`, `subjects-papers` matrix\n",
    "AP_tmp = sp.csr_matrix((np.ones_like(p_a[:, 0]), \n",
    "                        (vec_authors_trans(p_a[:, 1]) - num_papers, p_a[:, 0])), \n",
    "                       shape=(num_authors, num_papers))\n",
    "SP_tmp = sp.csr_matrix((np.ones_like(p_s[:, 0]),\n",
    "                        (vec_subjects_trans(p_s[:, 1]) - num_papers - num_authors, p_s[:, 0])),\n",
    "                       shape=(num_subjects, num_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6018x3025 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 10038 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<57x3025 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 3025 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PS_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_feats = AP_tmp.dot(paper_feats)\n",
    "subject_feats = SP_tmp.dot(paper_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sp.vstack((paper_feats, author_feats, subject_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9100x1903 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 989913 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper_feats: (3025, 1903)\n",
      "author_feats: (6018, 1903)\n",
      "subject_feats: (57, 1903)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'paper_feats: {paper_feats.shape}\\n'\\\n",
    "     f'author_feats: {author_feats.shape}\\n'\\\n",
    "     f'subject_feats: {subject_feats.shape}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 训练集、验证集、测试集分割\n",
    "\n",
    "- trian: 600\n",
    "- val: 300\n",
    "- test: 2125(the rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_train_val = np.random.choice(paper_db_inx, 300, replace=False)\n",
    "db_test = paper_db_inx[~np.isin(paper_db_inx, db_train_val)]\n",
    "dm_train_val = np.random.choice(paper_dm_inx, 300, replace=False)\n",
    "dm_test = paper_dm_inx[~np.isin(paper_dm_inx, dm_train_val)]\n",
    "wc_train_val = np.random.choice(paper_wc_inx, 300, replace=False)\n",
    "wc_test = paper_wc_inx[~np.isin(paper_wc_inx, wc_train_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300,), (694,))"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_train_val.shape, db_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300,), (761,))"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_train_val.shape, dm_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300,), (670,))"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_train_val.shape, wc_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_papers = np.concatenate((db_train_val[:200], dm_train_val[:200], wc_train_val[:200]))\n",
    "val_papers = np.concatenate((db_train_val[200:], dm_train_val[200:], wc_train_val[200:]))\n",
    "test_papers = np.concatenate((db_test, dm_test, wc_test))\n",
    "\n",
    "train_papers = vec_papers_trans(train_papers)\n",
    "val_papers = vec_papers_trans(val_papers)\n",
    "test_papers = vec_papers_trans(test_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train_papers)\n",
    "np.random.shuffle(val_papers)\n",
    "np.random.shuffle(test_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = targets[train_papers]\n",
    "val_targets = targets[val_papers]\n",
    "test_targets = targets[test_papers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 600\n",
      "val: 300\n",
      "test: 2125\n"
     ]
    }
   ],
   "source": [
    "print(f'train: {train_papers.shape[0]}\\n'\\\n",
    "     f'val: {val_papers.shape[0]}\\n'\\\n",
    "     f'test: {test_papers.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 数据离线存储\n",
    "\n",
    "利用pickle进行存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "acm_data = {'papers': papers, 'authors': authors, \n",
    "            'subjects': subjects, 'PA': PA, \n",
    "            'PS': PS, 'AP': AP, 'SP':SP, \n",
    "            'train_papers': train_papers,\n",
    "            'val_papers': val_papers,\n",
    "            'test_papers': test_papers,\n",
    "            'train_targets': train_targets,\n",
    "            'val_targets': val_targets,\n",
    "            'test_targets': test_targets,\n",
    "            'paper_feats': paper_feats,\n",
    "            'author_feats': author_feats,\n",
    "            'subject_feats': subject_feats,\n",
    "            'paper_dict': paper_dict,\n",
    "            'author_dict': author_dict,\n",
    "            'subject_dict': subject_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_path = Path('../datasets/ACM') / 'acm_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(acm_data, open(save_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

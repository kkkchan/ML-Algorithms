{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现Metapath2vec\n",
    "\n",
    "通过**numpy和gensim**进行实现\n",
    "\n",
    "用于处理异质网络的一种网络表示学习模型，采用：**元路径、随机游走、Skip-gram**\n",
    "\n",
    "论文下载地址：[metapath2vec: Scalable Representation Learning for Heterogeneous Networks \n",
    "](http://hanj.cs.illinois.edu/cs512/survey_slides/4-5-metapath2vec-KDD17.pdf)\n",
    "\n",
    "通过gensim库进行实现，包括两部分：**采样、Skip-gram处理**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入数据\n",
    "\n",
    "使用同HAN一样的小型异质数据集，ACM论文子集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "import gc\n",
    "import os\n",
    "import sklearn\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('../datasets/ACM/acm_data.pkl')\n",
    "data_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(data_path.open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'labels': array([0, 0, 0, ..., 2, 2, 2]),\n",
       " 'PSP': array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 1., ..., 1., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 1., ..., 1., 0., 1.],\n",
       "        [0., 1., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 1., ..., 1., 0., 1.]], dtype=float32),\n",
       " 'PAP': array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]], dtype=float32),\n",
       " 'train_mask': array([ True,  True,  True, ..., False, False, False]),\n",
       " 'val_mask': array([False, False, False, ..., False, False, False]),\n",
       " 'test_mask': array([False, False, False, ...,  True,  True,  True])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, PSP, PAP, train_mask, val_mask, test_mask = \\\n",
    "    data['features'], data['labels'], data['PSP'], data['PAP'], \\\n",
    "    data['train_mask'], data['val_mask'], data['test_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSP = PSP.astype(np.int)\n",
    "PAP = PAP.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), dtype('float32'), dtype('bool'), dtype('int64'))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PSP.dtype, PAP.dtype, train_mask.dtype, labels.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 采样\n",
    "\n",
    "共有两个元路径：**PAP，PSP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5581"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAP.nonzero()[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_adj(matrix):\n",
    "    '''\n",
    "    将链路信息矩阵转为字典形式，只存储存在链路的节点\n",
    "    '''\n",
    "    adj = {}\n",
    "    rows, cols = matrix.nonzero()\n",
    "    rows = rows.astype(np.str)\n",
    "    cols = cols.astype(np.str)\n",
    "    for row, col in zip(rows, cols):\n",
    "        adj.setdefault(row, [])\n",
    "        adj[row].append(col)\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAP_adj = matrix_to_adj(PAP)\n",
    "PSP_adj = matrix_to_adj(PSP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3025"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PSP_adj.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler(adj, walk_length, walks):\n",
    "    '''\n",
    "    进行随机游走采样，按照等概率进行邻接点选择\n",
    "    adj: 字典形式的邻节点信息结构\n",
    "    walks: 对于每个节点，以其作为开始节点独立构造游走序列的次数\n",
    "    walk_length: 每个游走序列的长度\n",
    "    '''\n",
    "    walk_sequences = []\n",
    "    for i in range(walks):\n",
    "        for ele in adj.keys():\n",
    "            tmp_walk_sequence = []\n",
    "            cur_node = ele\n",
    "            for j in range(walk_length):\n",
    "                tmp_walk_sequence.append(cur_node)\n",
    "                cur_node = random.choice(adj[cur_node])\n",
    "            walk_sequences.append(tmp_walk_sequence)\n",
    "    return walk_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_length = 100\n",
    "walks = 100\n",
    "latent_dimension = 128\n",
    "neg_sampling = 5\n",
    "min_count = 1\n",
    "window = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAP_sequences = sampler(PAP_adj, walk_length=walk_length, walks=walks)\n",
    "PSP_sequences = sampler(PSP_adj, walk_length=walk_length, walks=walks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 建模\n",
    "\n",
    "上一步已经完成了对节点的随机游走采样，接下来可以将多个元路径合并为一个，然后输入进Skip-gram模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并序列\n",
    "sequences = PAP_sequences + PSP_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "605000"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练并生成模型\n",
    "model = gensim.models.word2vec.Word2Vec(sentences=sequences, \n",
    "                                        size=128, \n",
    "                                        window=window,\n",
    "                                        workers=os.cpu_count(),\n",
    "                                        sg=1, # skip-gram\n",
    "                                        hs=0, # negtive sampling\n",
    "                                        negative=5,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('metapath2vec.model')\n",
    "model.wv.save('metapath2vec.wv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv\n",
    "graph_features = model.wv.vectors\n",
    "# 获取与graph_features相对应的index，是乱序的\n",
    "graph_index = model.wv.index2word\n",
    "graph_index = [int(ele) for ele in graph_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新对graph_features排序，使其符合从0-3024的排序\n",
    "re_index = np.argsort(graph_index)\n",
    "graph_features = graph_features[re_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, val, test对应的index\n",
    "train_index = np.arange(3025)[train_mask]\n",
    "val_index = np.arange(3025)[val_mask]\n",
    "test_index = np.arange(3025)[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 128)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_features[val_index].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3971764705882353"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只利用图特征训练\n",
    "xgb_clf = xgboost.XGBClassifier(max_depth=2, n_estimators=200)\n",
    "xgb_clf.fit(graph_features[train_index], labels[train_index])\n",
    "y_pred = xgb_clf.predict(graph_features[test_index])\n",
    "sklearn.metrics.accuracy_score(y_pred, labels[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7534117647058823"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只利用paper自带特征训练\n",
    "xgb_clf = xgboost.XGBClassifier(max_depth=2, n_estimators=200)\n",
    "xgb_clf.fit(features[train_index], labels[train_index])\n",
    "y_pred = xgb_clf.predict(features[test_index])\n",
    "sklearn.metrics.accuracy_score(y_pred, labels[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6672941176470588"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用组合特征训练\n",
    "mixed_features = np.concatenate([features, graph_features], axis=1)\n",
    "xgb_clf = xgboost.XGBClassifier(max_depth=2, n_estimators=200)\n",
    "xgb_clf.fit(mixed_features[train_index], labels[train_index])\n",
    "y_pred = xgb_clf.predict(mixed_features[test_index])\n",
    "sklearn.metrics.accuracy_score(y_pred, labels[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34494117647058825"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC(gamma='scale')\n",
    "svm_clf.fit(graph_features[train_index], labels[train_index])\n",
    "y_pred = svm_clf.predict(graph_features[test_index])\n",
    "sklearn.metrics.accuracy_score(y_pred, labels[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7242352941176471"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC(gamma='scale')\n",
    "svm_clf.fit(features[train_index], labels[train_index])\n",
    "y_pred = svm_clf.predict(features[test_index])\n",
    "sklearn.metrics.accuracy_score(y_pred, labels[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7063529411764706"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC(gamma='scale')\n",
    "svm_clf.fit(mixed_features[train_index], labels[train_index])\n",
    "y_pred = svm_clf.predict(mixed_features[test_index])\n",
    "sklearn.metrics.accuracy_score(y_pred, labels[test_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
